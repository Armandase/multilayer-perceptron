preprocessing:
  data_path: 'correction/data.csv' # Path of the dataset
  data_train_path: 'data_training.csv' # Path of the train dataset
  data_test_path: 'data_test.csv' # Path of the test dataset
  force_dataset_creation: false # Force the creation of the dataset
  path_save_data: '/home/armand/42/multilayer_perceptron' # Path to save the dataset

  shuffle: true # Shuffling the data
  seed: -1 # seed uses with 'random' package (-1 for disable it)
  train_prop: 0.8 # Proportion of the dataset used for training
  test_prop: 0.2 # Proportion of the dataset used for validation

  header: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',
    'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
    'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',
    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',
    'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
    'fractal_dimension_se', 'radius_worst', 'texture_worst',
    'perimeter_worst', 'area_worst', 'smoothness_worst',
    'compactness_worst', 'concavity_worst', 'concave points_worst',
    'symmetry_worst', 'fractal_dimension_worst']

model:
  input_len: 30
  model_path: 'save_model/model.json'
  epochs: 200
  batch_size: 64
  learning_rate: 0.05
  nb_output: 2
  
  callbacks:
    enable_early_stop: False
    early_stop: 0.01
    scheduler: 0.5
  
    enable_save_best_model: True
    best_model_path: 'save_model/best_model.json'

  layers:
    - name: "sigmoid"
      output: 64
    # - name: "dropout"
      # output: 0.5
    - name: "sigmoid"
      output: 32
    # - name: "dropout"
      # output: 0.3
    - name: "sigmoid"
      output: 16
    # - name: "dropout"
      # output: 0.2
  
  optimizer: 'rsmprop'

predict:
  data_path: 'correction/data_test.csv' # Path of the dataset
  model_path: 'save_model/model.json'
  seed: -1

verbose: True
