preprocessing:
  data_path: 'data.csv' # Path of the dataset
  data_train_path: 'correction/data_train.csv' # Path of the train dataset
  data_test_path: 'correction/data_test.csv' # Path of the test dataset
  force_dataset_creation: true # Force the creation of the dataset
  path_save_data: '/home/armand/42/multilayer_perceptron' # Path to save the dataset

  shuffle: true # Shuffling the data
  seed: -1 # seed uses with 'random' package (-1 for disable it)
  train_prop: 0.8 # Proportion of the dataset used for training
  test_prop: 0.2 # Proportion of the dataset used for validation

  header: ['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',
    'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
    'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',
    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',
    'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
    'fractal_dimension_se', 'radius_worst', 'texture_worst',
    'perimeter_worst', 'area_worst', 'smoothness_worst',
    'compactness_worst', 'concavity_worst', 'concave points_worst',
    'symmetry_worst', 'fractal_dimension_worst']

model:
  intput_len: 30
  model_path: 'save_model/model.json'
  epochs: 5000
  batch_size: 16
  learning_rate: 0.001
  nb_output: 2
  
  callbacks:
    enable_early_stop: True
    early_stop: 0.0000001
  
    enable_save_best_model: True
    best_model_path: 'save_model/best_model.json'


  fc1: 64
  fc2: 32
  fc3: 32

  dropout_rate: 0.4

  # fc1: 64
  # fc2: 256
  # fc3: 128
  # fc4: 128
  # fc5: 64

predict:
  data_path: 'correction/data_test.csv' # Path of the dataset
  model_path: 'save_model/model.json'
  seed: -1

verbose: True
